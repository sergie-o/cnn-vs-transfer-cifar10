{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAltC2wIchwE",
        "outputId": "ea2ee5ac-f380-445e-b190-e251ebd27aad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_96_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 40ms/step - accuracy: 0.3589 - loss: 2.0515 - val_accuracy: 0.7751 - val_loss: 0.6717\n",
            "Epoch 2/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 17ms/step - accuracy: 0.7371 - loss: 0.7850 - val_accuracy: 0.8140 - val_loss: 0.5345\n",
            "Epoch 3/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 18ms/step - accuracy: 0.7854 - loss: 0.6319 - val_accuracy: 0.8315 - val_loss: 0.4871\n",
            "Epoch 4/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 17ms/step - accuracy: 0.8063 - loss: 0.5709 - val_accuracy: 0.8406 - val_loss: 0.4592\n",
            "Epoch 5/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 18ms/step - accuracy: 0.8193 - loss: 0.5311 - val_accuracy: 0.8477 - val_loss: 0.4427\n",
            "Epoch 6/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 17ms/step - accuracy: 0.8255 - loss: 0.5049 - val_accuracy: 0.8493 - val_loss: 0.4331\n",
            "Epoch 7/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 18ms/step - accuracy: 0.8350 - loss: 0.4819 - val_accuracy: 0.8528 - val_loss: 0.4236\n",
            "Epoch 8/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.8353 - loss: 0.4784 - val_accuracy: 0.8554 - val_loss: 0.4160\n",
            "Epoch 9/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.8445 - loss: 0.4569 - val_accuracy: 0.8581 - val_loss: 0.4105\n",
            "Epoch 10/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 16ms/step - accuracy: 0.8486 - loss: 0.4424 - val_accuracy: 0.8588 - val_loss: 0.4069\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load CIFAR-10\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# One-hot encode labels\n",
        "y_train_cat = to_categorical(y_train, 10)\n",
        "y_test_cat  = to_categorical(y_test, 10)\n",
        "\n",
        "# Build TensorFlow datasets\n",
        "batch_size = 64\n",
        "\n",
        "def preprocess(image, label):\n",
        "    image = tf.image.resize(image, (96, 96))       # resize here\n",
        "    image = preprocess_input(image)                # mobilenet preprocess\n",
        "    return image, label\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train_cat))\n",
        "train_ds = train_ds.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_ds = train_ds.shuffle(10000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test_cat))\n",
        "test_ds = test_ds.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_ds = test_ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load base MobileNetV2 (pretrained on ImageNet, exclude top)\n",
        "base_model = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(96,96,3))\n",
        "base_model.trainable = False  # Freeze base for transfer learning\n",
        "\n",
        "# Add custom classification head\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.3)(x)  # regularization\n",
        "output = Dense(10, activation=\"softmax\")(x)  # CIFAR-10 has 10 classes\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Compile\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-4),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Train first phase (frozen base)\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=test_ds,\n",
        "    epochs=10\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"mobilenetv2_colab_v1.keras\")"
      ],
      "metadata": {
        "id": "hD5YUegacrIh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load CIFAR-10\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# One-hot encode labels (since we'll use categorical_crossentropy)\n",
        "y_train_cat = to_categorical(y_train, 10)\n",
        "y_test_cat  = to_categorical(y_test, 10)\n",
        "\n",
        "# ===== Settings =====\n",
        "batch_size = 64\n",
        "IMG_SIZE = 224   # EfficientNetB0 default. If Colab OOMs, try 128 or 96.\n",
        "\n",
        "# tf.data preprocessing for EfficientNetB0\n",
        "# (Modern Keras EfficientNet includes Rescaling(1./255) internally,\n",
        "#  so feed 0..255 floats; no external preprocess needed.)\n",
        "def preprocess(image, label):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "    return image, label\n",
        "\n",
        "train_ds = (tf.data.Dataset.from_tensor_slices((X_train, y_train_cat))\n",
        "            .shuffle(10000)\n",
        "            .map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "            .batch(batch_size)\n",
        "            .prefetch(tf.data.AUTOTUNE))\n",
        "\n",
        "test_ds = (tf.data.Dataset.from_tensor_slices((X_test, y_test_cat))\n",
        "           .map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "           .batch(batch_size)\n",
        "           .prefetch(tf.data.AUTOTUNE))\n",
        "\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Base: EfficientNetB0 (pretrained, no top)\n",
        "base_model = EfficientNetB0(weights=\"imagenet\",\n",
        "                            include_top=False,\n",
        "                            input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "base_model.trainable = False  # freeze for transfer learning\n",
        "\n",
        "# Head\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.3)(x)           # regularization\n",
        "output = Dense(10, activation=\"softmax\")(x)  # CIFAR-10 has 10 classes\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Compile\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-4),\n",
        "    loss=\"categorical_crossentropy\",  # matches one-hot labels\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Train first phase (frozen base)\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=test_ds,\n",
        "    epochs=10\n",
        ")\n",
        "\n",
        "# Optional: fine-tune the top of the base with a lower LR\n",
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:-30]:   # unfreeze last ~30 layers\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer=Adam(1e-5),\n",
        "              loss=\"categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "history_ft = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=test_ds,\n",
        "    epochs=10\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ub-r9W0scsoj",
        "outputId": "7e7ef277-1751-4730-bde2-b1f3cc1c86dc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 107ms/step - accuracy: 0.4527 - loss: 1.6956 - val_accuracy: 0.8253 - val_loss: 0.6779\n",
            "Epoch 2/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 72ms/step - accuracy: 0.8059 - loss: 0.6803 - val_accuracy: 0.8527 - val_loss: 0.5026\n",
            "Epoch 3/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 74ms/step - accuracy: 0.8328 - loss: 0.5383 - val_accuracy: 0.8658 - val_loss: 0.4404\n",
            "Epoch 4/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 74ms/step - accuracy: 0.8458 - loss: 0.4805 - val_accuracy: 0.8731 - val_loss: 0.4075\n",
            "Epoch 5/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 72ms/step - accuracy: 0.8555 - loss: 0.4467 - val_accuracy: 0.8782 - val_loss: 0.3854\n",
            "Epoch 6/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 72ms/step - accuracy: 0.8587 - loss: 0.4270 - val_accuracy: 0.8812 - val_loss: 0.3703\n",
            "Epoch 7/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 72ms/step - accuracy: 0.8644 - loss: 0.4059 - val_accuracy: 0.8825 - val_loss: 0.3590\n",
            "Epoch 8/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 72ms/step - accuracy: 0.8687 - loss: 0.3921 - val_accuracy: 0.8843 - val_loss: 0.3498\n",
            "Epoch 9/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 74ms/step - accuracy: 0.8725 - loss: 0.3827 - val_accuracy: 0.8853 - val_loss: 0.3427\n",
            "Epoch 10/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 73ms/step - accuracy: 0.8745 - loss: 0.3727 - val_accuracy: 0.8879 - val_loss: 0.3365\n",
            "Epoch 1/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 121ms/step - accuracy: 0.8369 - loss: 0.5247 - val_accuracy: 0.8968 - val_loss: 0.3259\n",
            "Epoch 2/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 86ms/step - accuracy: 0.8727 - loss: 0.3925 - val_accuracy: 0.9061 - val_loss: 0.2887\n",
            "Epoch 3/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 84ms/step - accuracy: 0.8818 - loss: 0.3499 - val_accuracy: 0.9103 - val_loss: 0.2690\n",
            "Epoch 4/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - accuracy: 0.8941 - loss: 0.3171 - val_accuracy: 0.9156 - val_loss: 0.2543\n",
            "Epoch 5/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 87ms/step - accuracy: 0.8970 - loss: 0.2979 - val_accuracy: 0.9184 - val_loss: 0.2429\n",
            "Epoch 6/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 86ms/step - accuracy: 0.9009 - loss: 0.2871 - val_accuracy: 0.9197 - val_loss: 0.2336\n",
            "Epoch 7/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 85ms/step - accuracy: 0.9045 - loss: 0.2759 - val_accuracy: 0.9212 - val_loss: 0.2263\n",
            "Epoch 8/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 85ms/step - accuracy: 0.9135 - loss: 0.2570 - val_accuracy: 0.9231 - val_loss: 0.2198\n",
            "Epoch 9/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 86ms/step - accuracy: 0.9154 - loss: 0.2539 - val_accuracy: 0.9253 - val_loss: 0.2145\n",
            "Epoch 10/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 84ms/step - accuracy: 0.9183 - loss: 0.2398 - val_accuracy: 0.9267 - val_loss: 0.2101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"efficientnetb0_colab_v1.keras\")"
      ],
      "metadata": {
        "id": "MMCqAQx0c17V"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = model.evaluate( test_ds, verbose=0)\n",
        "print(f\"Test accuracy: {acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiTmhXNmexbQ",
        "outputId": "528740c6-a288-4acf-da35-d1cb35dadcc8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.9267\n"
          ]
        }
      ]
    }
  ]
}